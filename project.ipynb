{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80197891-c3a7-4fd8-a75b-f2f9b9712f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Basic libraries\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "\n",
    "\n",
    "#NLTK libraries\n",
    "import nltk\n",
    "import re\n",
    "import string\n",
    "from wordcloud import WordCloud,STOPWORDS\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Machine Learning libraries\n",
    "import sklearn \n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB \n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn import svm, datasets\n",
    "from sklearn import preprocessing \n",
    "\n",
    "\n",
    "#Metrics libraries\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "#Visualization libraries\n",
    "import matplotlib.pyplot as plt \n",
    "from matplotlib import rcParams\n",
    "import seaborn as sns\n",
    "from textblob import TextBlob\n",
    "from plotly import tools\n",
    "import plotly.graph_objs as go\n",
    "from plotly.offline import iplot\n",
    "%matplotlib inline\n",
    "\n",
    "#Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#Other miscellaneous libraries\n",
    "from scipy import interp\n",
    "from itertools import cycle\n",
    "import cufflinks as cf\n",
    "from collections import defaultdict\n",
    "from collections import Counter\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b01b54-6266-45a3-8394-1e91d96b4632",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_reviews = pd.read_csv('../input/amazon-music-reviews/Musical_instruments_reviews.csv')\n",
    "## print shape of dataset with rows and columns and information \n",
    "print (\"The shape of the  data is (row, column):\"+ str(raw_reviews.shape))\n",
    "print (raw_reviews.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0344ed29-87c5-4cd9-a4c7-4589ac9c343d",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26241da4-f2a8-4a14-89a1-70ac199a0ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a copy\n",
    "process_reviews=raw_reviews.copy()\n",
    "\n",
    "#Checking for null values\n",
    "process_reviews.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5645f1f1-9259-4dac-ba4a-1d93278411e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "process_reviews['reviewText']=process_reviews['reviewText'].fillna('Missing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4250db89-f638-4f26-b2fd-fcd32ea621ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "process_reviews['reviews']=process_reviews['reviewText']+process_reviews['summary']\n",
    "process_reviews=process_reviews.drop(['reviewText', 'summary'], axis=1)\n",
    "process_reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3208f28d-ae42-4e0a-bb17-6eba45251a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Figuring out the distribution of categories\n",
    "process_reviews['overall'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ddcf5f-0c05-44ff-821a-224707328fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(row):\n",
    "    \n",
    "    '''This function returns sentiment value based on the overall ratings from the user'''\n",
    "    \n",
    "    if row['overall'] == 3.0:\n",
    "        val = 'Neutral'\n",
    "    elif row['overall'] == 1.0 or row['overall'] == 2.0:\n",
    "        val = 'Negative'\n",
    "    elif row['overall'] == 4.0 or row['overall'] == 5.0:\n",
    "        val = 'Positive'\n",
    "    else:\n",
    "        val = -1\n",
    "    return val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1edfca8d-0aff-45fa-9113-5637c407786f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Applying the function in our new column\n",
    "process_reviews['sentiment'] = process_reviews.apply(f, axis=1)\n",
    "process_reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b9b0b49-e337-4c22-a43b-5915ef1a866d",
   "metadata": {},
   "outputs": [],
   "source": [
    "process_reviews['sentiment'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34fe0c99-5920-418a-a0ec-3dcf47dafb3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# new data frame which has date and year\n",
    "new = process_reviews[\"reviewTime\"].str.split(\",\", n = 1, expand = True) \n",
    "  \n",
    "# making separate date column from new data frame \n",
    "process_reviews[\"date\"]= new[0] \n",
    "  \n",
    "# making separate year column from new data frame \n",
    "process_reviews[\"year\"]= new[1] \n",
    "\n",
    "process_reviews=process_reviews.drop(['reviewTime'], axis=1)\n",
    "process_reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e85896b-28c4-4a65-832f-cbed51a11b17",
   "metadata": {},
   "outputs": [],
   "source": [
    " Splitting the date \n",
    "new1 = process_reviews[\"date\"].str.split(\" \", n = 1, expand = True) \n",
    "  \n",
    "# adding month to the main dataset \n",
    "process_reviews[\"month\"]= new1[0] \n",
    "  \n",
    "# adding day to the main dataset \n",
    "process_reviews[\"day\"]= new1[1] \n",
    "\n",
    "process_reviews=process_reviews.drop(['date'], axis=1)\n",
    "process_reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d21b1be0-01fc-404a-9184-bcc0384a7145",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset based on comma and square bracket \n",
    "new1 = process_reviews[\"helpful\"].str.split(\",\", n = 1, expand = True)\n",
    "new2 = new1[0].str.split(\"[\", n = 1, expand = True)\n",
    "new3 = new1[1].str.split(\"]\", n = 1, expand = True)\n",
    "\n",
    "#Resetting the index\n",
    "new2.reset_index(drop=True, inplace=True)\n",
    "new3.reset_index(drop=True, inplace=True)\n",
    "\n",
    "#Dropping empty columns due to splitting \n",
    "new2=new2.drop([0], axis=1)\n",
    "new3=new3.drop([1], axis=1)\n",
    "\n",
    "#Concatenating the splitted columns\n",
    "helpful=pd.concat([new2, new3], axis=1)\n",
    "\n",
    "\n",
    "# I found few spaces in new3, so it is better to strip all the values to find the rate\n",
    "def trim_all_columns(df):\n",
    "    \"\"\"\n",
    "    Trim whitespace from ends of each value across all series in dataframe\n",
    "    \"\"\"\n",
    "    trim_strings = lambda x: x.strip() if isinstance(x, str) else x\n",
    "    return df.applymap(trim_strings)\n",
    "\n",
    "#Applying the function\n",
    "helpful= trim_all_columns(helpful)\n",
    "\n",
    "#Converting into integer types\n",
    "helpful[0]=helpful[0].astype(str).astype(int)\n",
    "helpful[1]=helpful[1].astype(str).astype(int)\n",
    "\n",
    "#Dividing the two columns, we have 0 in the second columns when dvided gives error, so I'm ignoring those errors\n",
    "try:\n",
    "  helpful['result'] = helpful[1]/helpful[0]\n",
    "except ZeroDivisionError:\n",
    "  helpful['result']=0\n",
    "\n",
    "#Filling the NaN values(created due to dividing) with 0\n",
    "helpful['result'] = helpful['result'].fillna(0)\n",
    "\n",
    "#Rounding of the results to two decimal places\n",
    "helpful['result']=helpful['result'].round(2) \n",
    "\n",
    "#Attaching the results to a new column of the main dataframe\n",
    "process_reviews['helpful_rate']=helpful['result']\n",
    "\n",
    "#dropping the helpful column from main dataframe\n",
    "process_reviews=process_reviews.drop(['helpful'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e8c587b-4381-4da5-b512-ceef4fbf7ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "process_reviews.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9734efdc-a636-447e-bb08-c438e96941d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "process_reviews['helpful_rate'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e564a798-401c-4e32-a21c-0a3029c48000",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing unnecessary columns\n",
    "process_reviews=process_reviews.drop(['reviewerName','unixReviewTime'], axis=1)\n",
    "#Creating a copy \n",
    "clean_reviews=process_reviews.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55bbdfa9-2c81-491d-9f0e-92ecc9b76890",
   "metadata": {},
   "outputs": [],
   "source": [
    "def review_cleaning(text):\n",
    "    '''Make text lowercase, remove text in square brackets,remove links,remove punctuation\n",
    "    and remove words containing numbers.'''\n",
    "    text = str(text).lower()\n",
    "    text = re.sub('\\[.*?\\]', '', text)\n",
    "    text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n",
    "    text = re.sub('<.*?>+', '', text)\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
    "    text = re.sub('\\n', '', text)\n",
    "    text = re.sub('\\w*\\d\\w*', '', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a640740e-a228-4eb5-b263-a9991dc709b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "process_reviews['reviews']=process_reviews['reviews'].apply(lambda x:review_cleaning(x))\n",
    "process_reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db295bf4-f8cd-44ca-830d-5e91ceb2b818",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words= ['yourselves', 'between', 'whom', 'itself', 'is', \"she's\", 'up', 'herself', 'here', 'your', 'each', \n",
    "             'we', 'he', 'my', \"you've\", 'having', 'in', 'both', 'for', 'themselves', 'are', 'them', 'other',\n",
    "             'and', 'an', 'during', 'their', 'can', 'yourself', 'she', 'until', 'so', 'these', 'ours', 'above', \n",
    "             'what', 'while', 'have', 're', 'more', 'only', \"needn't\", 'when', 'just', 'that', 'were', \"don't\", \n",
    "             'very', 'should', 'any', 'y', 'isn', 'who',  'a', 'they', 'to', 'too', \"should've\", 'has', 'before',\n",
    "             'into', 'yours', \"it's\", 'do', 'against', 'on',  'now', 'her', 've', 'd', 'by', 'am', 'from', \n",
    "             'about', 'further', \"that'll\", \"you'd\", 'you', 'as', 'how', 'been', 'the', 'or', 'doing', 'such',\n",
    "             'his', 'himself', 'ourselves',  'was', 'through', 'out', 'below', 'own', 'myself', 'theirs', \n",
    "             'me', 'why', 'once',  'him', 'than', 'be', 'most', \"you'll\", 'same', 'some', 'with', 'few', 'it',\n",
    "             'at', 'after', 'its', 'which', 'there','our', 'this', 'hers', 'being', 'did', 'of', 'had', 'under',\n",
    "             'over','again', 'where', 'those', 'then', \"you're\", 'i', 'because', 'does', 'all']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "143847ff-d419-46ae-b649-d4b3acbefb09",
   "metadata": {},
   "outputs": [],
   "source": [
    "process_reviews['reviews'] = process_reviews['reviews'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop_words)]))\n",
    "process_reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16822794-44dd-40d5-9b7e-9e04a4e7b9d2",
   "metadata": {},
   "outputs": [],
   "source": [
    " calling the label encoder function\n",
    "label_encoder = preprocessing.LabelEncoder() \n",
    "  \n",
    "# Encode labels in column 'sentiment'. \n",
    "process_reviews['sentiment']= label_encoder.fit_transform(process_reviews['sentiment']) \n",
    "  \n",
    "process_reviews['sentiment'].unique() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7cd060d-a015-471f-bb79-5e4a4d9c52df",
   "metadata": {},
   "outputs": [],
   "source": [
    "process_reviews['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d994dd86-2855-4b49-a0e1-2262a26cb70c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting 'reviews' for processing\n",
    "review_features=process_reviews.copy()\n",
    "review_features=review_features[['reviews']].reset_index(drop=True)\n",
    "review_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f68f7bd3-c289-48e3-856e-c13be1bf8c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Performing stemming on the review dataframe\n",
    "ps = PorterStemmer()\n",
    "\n",
    "#splitting and adding the stemmed words except stopwords\n",
    "corpus = []\n",
    "for i in range(0, len(review_features)):\n",
    "    review = re.sub('[^a-zA-Z]', ' ', review_features['reviews'][i])\n",
    "    review = review.split()\n",
    "    review = [ps.stem(word) for word in review if not word in stop_words]\n",
    "    review = ' '.join(review)\n",
    "    corpus.append(review)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dce7ee0-f91f-44d6-87db-a874b46a3f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus[3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad776b7a-719a-4e87-a7d5-b5541bf6a946",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(max_features=5000,ngram_range=(2,2))\n",
    "# TF-IDF feature matrix\n",
    "X= tfidf_vectorizer.fit_transform(review_features['reviews'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "401045e5-2819-4c7b-9380-96e80e73bd16",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e59dfb7-a714-4024-bf24-1a7933fbc324",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting the target variable(encoded)\n",
    "y=process_reviews['sentiment']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5851580-e297-4611-9517-aa8f59c3993a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Original dataset shape : {Counter(y)}')\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "X_res, y_res = smote.fit_resample(X, y)\n",
    "\n",
    "print(f'Resampled dataset shape {Counter(y_res)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51082356-acac-47fd-be97-942b3db4fbc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Divide the dataset into Train and Test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_res, y_res, test_size=0.25, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad63684-cd26-47a1-97b2-de714b465971",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    \n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range (cm.shape[0]):\n",
    "        for j in range (cm.shape[1]):\n",
    "            plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "050ffbbe-16bf-44fd-ba85-8110809ecb8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating the objects\n",
    "logreg_cv = LogisticRegression(random_state=0)\n",
    "dt_cv=DecisionTreeClassifier()\n",
    "knn_cv=KNeighborsClassifier()\n",
    "svc_cv=SVC()\n",
    "nb_cv=BernoulliNB()\n",
    "cv_dict = {0: 'Logistic Regression', 1: 'Decision Tree',2:'KNN',3:'SVC',4:'Naive Bayes'}\n",
    "cv_models=[logreg_cv,dt_cv,knn_cv,svc_cv,nb_cv]\n",
    "\n",
    "\n",
    "for i,model in enumerate(cv_models):\n",
    "    print(\"{} Test Accuracy: {}\".format(cv_dict[i],cross_val_score(model, X, y, cv=10, scoring ='accuracy').mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b0ba883-ef85-4200-88a0-8b0e86993547",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'C': np.logspace(-4, 4, 50),\n",
    "             'penalty':['l1', 'l2']}\n",
    "clf = GridSearchCV(LogisticRegression(random_state=0), param_grid,cv=5, verbose=0,n_jobs=-1)\n",
    "best_model = clf.fit(X_train,y_train)\n",
    "print(best_model.best_estimator_)\n",
    "print(\"The mean accuracy of the model is:\",best_model.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d4ae92-2462-4ede-8ac9-ef6bb1e25ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression(C=10000.0, random_state=0)\n",
    "logreg.fit(X_train, y_train)\n",
    "y_pred = logreg.predict(X_test)\n",
    "print('Accuracy of logistic regression classifier on test set: {:.2f}'.format(logreg.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c31712-5b9d-42ee-8301-7a92f570a02b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = metrics.confusion_matrix(y_test, y_pred)\n",
    "plot_confusion_matrix(cm, classes=['Negative','Neutral','Positive'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa68ca4e-20ed-42bd-afae-2850c53d1fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Classification Report:\\n\",classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d4c804-cb22-4b64-b0e0-1c5aa216dde8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Binarizing the target feature\n",
    "y = label_binarize(y, classes=[0, 1, 2])\n",
    "n_classes = y.shape[1]\n",
    "\n",
    "#Train-Test split(80:20)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2,\n",
    "                                                    random_state=0)\n",
    "\n",
    "#OneVsRestClassifier\n",
    "classifier = OneVsRestClassifier(svm.SVC(kernel='linear', probability=True,\n",
    "                                 random_state=10))\n",
    "y_score = classifier.fit(X_train, y_train).decision_function(X_test)\n",
    "\n",
    "#Computing TPR and FPR\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_score[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Compute micro-average ROC curve and ROC area\n",
    "fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test.ravel(), y_score.ravel())\n",
    "roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "    \n",
    "# aggregate all false positive rates\n",
    "all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n",
    "\n",
    "# interpolate all ROC curves at this points\n",
    "mean_tpr = np.zeros_like(all_fpr)\n",
    "for i in range(n_classes):\n",
    "    mean_tpr += interp(all_fpr, fpr[i], tpr[i])\n",
    "\n",
    "# Finally average it and compute AUC\n",
    "mean_tpr /= n_classes\n",
    "\n",
    "fpr[\"macro\"] = all_fpr\n",
    "tpr[\"macro\"] = mean_tpr\n",
    "roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n",
    "\n",
    "# Plot all ROC curves\n",
    "plt.figure()\n",
    "plt.plot(fpr[\"micro\"], tpr[\"micro\"],\n",
    "         label='micro-average ROC curve (area = {0:0.2f})'\n",
    "               ''.format(roc_auc[\"micro\"]),\n",
    "         color='deeppink', linestyle=':', linewidth=4)\n",
    "\n",
    "plt.plot(fpr[\"macro\"], tpr[\"macro\"],\n",
    "         label='macro-average ROC curve (area = {0:0.2f})'\n",
    "               ''.format(roc_auc[\"macro\"]),\n",
    "         color='navy', linestyle=':', linewidth=4)\n",
    "\n",
    "colors = cycle(['aqua', 'darkorange', 'cornflowerblue'])\n",
    "for i, color in zip(range(n_classes), colors):\n",
    "    plt.plot(fpr[i], tpr[i], color=color, lw=4,\n",
    "             label='ROC curve of class {0} (area = {1:0.2f})'\n",
    "             ''.format(i, roc_auc[i]))\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=4)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic to multi-class')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3830c9d2-7f60-4bda-a118-851f83cfc5ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
